version: '3.8'

services:
  vllm-server-chinda-qwen3-0.6b:
    image: vllm/vllm-openai:latest
    shm_size: 32g
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # Use 1 GPU for 0.6B model
              capabilities: [gpu]
    volumes:
      - /home/saiuser/disk6/ms-swift-merged/chinda-qwen3-0.6b-1-2-20250528-20_00-dpo:/models
    ports:
      - "8801:8000"  # Map internal port 8000 to external 8801
    environment:
      - NCCL_IGNORE_DISABLED_P2P=1
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://0.0.0.0:8000/v1/models" ]
      interval: 30s
      timeout: 5s
      retries: 20
    command:
      - --model=/models
      - --tensor-parallel-size=1
      - --served-model-name=chinda-qwen3-0.6b
      - --trust-remote-code
    restart: unless-stopped